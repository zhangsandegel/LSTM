{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Classification","metadata":{}},{"cell_type":"code","source":"# load packages\nimport pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\nimport platform\nif platform.system() == \"Windows\":\n    plt.rcParams['font.family'] = ['SimHei'] # Windows\nelif platform.system() == \"Darwin\":\n    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # MacOS\nplt.rcParams['axes.unicode_minus']=False \n\n\nd_list = []\nfolder = '/kaggle/input/gas-sensor-array-drift-dataset'\nfiles = sorted([i for i in os.listdir(folder) if i.endswith('.dat')])\nfor file in files:\n    print(file)\n    df = pd.read_csv(os.path.join(folder,file),header=None,sep=' ')\n    df = df.dropna(axis=1)\n    df = df.astype(str).applymap(lambda x:x.split(':')[-1])\n    df['label'] = df[0].map(lambda x:int(x.split(';')[0]))\n    df['var'] = df[0].map(lambda x:float(x.split(';')[1]))\n    df = df.drop(columns=[0])\n    df = df.astype(float)\n    d_list.append(df)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-21T08:42:25.487516Z","iopub.execute_input":"2023-07-21T08:42:25.488018Z","iopub.status.idle":"2023-07-21T08:42:29.175383Z","shell.execute_reply.started":"2023-07-21T08:42:25.487978Z","shell.execute_reply":"2023-07-21T08:42:29.174466Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"batch1.dat\nbatch10.dat\nbatch2.dat\nbatch3.dat\nbatch4.dat\nbatch5.dat\nbatch6.dat\nbatch7.dat\nbatch8.dat\nbatch9.dat\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.concat(d_list,axis=0).reset_index(drop=True)\ndf = df[~df['label'].isin([0])]\ndf['label'] = df['label'] - 1","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:43:22.313922Z","iopub.execute_input":"2023-07-21T08:43:22.314369Z","iopub.status.idle":"2023-07-21T08:43:22.364196Z","shell.execute_reply.started":"2023-07-21T08:43:22.314333Z","shell.execute_reply":"2023-07-21T08:43:22.362910Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX = scaler.fit_transform(df.iloc[:,:128])\nX = X.reshape(-1,X.shape[1],1)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:43:23.814593Z","iopub.execute_input":"2023-07-21T08:43:23.815530Z","iopub.status.idle":"2023-07-21T08:43:23.844893Z","shell.execute_reply.started":"2023-07-21T08:43:23.815490Z","shell.execute_reply":"2023-07-21T08:43:23.843559Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y = df.iloc[:,128].values","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:43:24.563834Z","iopub.execute_input":"2023-07-21T08:43:24.564255Z","iopub.status.idle":"2023-07-21T08:43:24.570363Z","shell.execute_reply.started":"2023-07-21T08:43:24.564200Z","shell.execute_reply":"2023-07-21T08:43:24.569131Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,128].unique()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:43:25.200042Z","iopub.execute_input":"2023-07-21T08:43:25.200475Z","iopub.status.idle":"2023-07-21T08:43:25.209485Z","shell.execute_reply.started":"2023-07-21T08:43:25.200438Z","shell.execute_reply":"2023-07-21T08:43:25.208273Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([0., 1., 2., 3., 4., 5.])"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.utils import to_categorical\n\n# 数据预处理\n# 对类别标签y进行独热编码\ny_encoded = to_categorical(y)\n\n# 拆分数据集为训练集和测试集（8:2）\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# 构建LSTM多分类模型\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))  # 假设有3个类别，输出层使用softmax激活函数\n\n# 编译模型\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())\n# 训练模型\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test,y_test))\n\n# 评估模型性能\nloss = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:43:26.701308Z","iopub.execute_input":"2023-07-21T08:43:26.701724Z","iopub.status.idle":"2023-07-21T08:47:27.721292Z","shell.execute_reply.started":"2023-07-21T08:43:26.701691Z","shell.execute_reply":"2023-07-21T08:47:27.720179Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm (LSTM)                 (None, 64)                16896     \n                                                                 \n dense (Dense)               (None, 32)                2080      \n                                                                 \n dense_1 (Dense)             (None, 6)                 198       \n                                                                 \n=================================================================\nTotal params: 19,174\nTrainable params: 19,174\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/10\n347/347 [==============================] - 26s 68ms/step - loss: 1.7539 - accuracy: 0.2227 - val_loss: 1.7382 - val_accuracy: 0.2137\nEpoch 2/10\n347/347 [==============================] - 23s 65ms/step - loss: 1.6587 - accuracy: 0.2878 - val_loss: 1.6642 - val_accuracy: 0.2736\nEpoch 3/10\n347/347 [==============================] - 22s 64ms/step - loss: 1.3218 - accuracy: 0.4770 - val_loss: 0.9814 - val_accuracy: 0.6509\nEpoch 4/10\n347/347 [==============================] - 23s 65ms/step - loss: 0.9661 - accuracy: 0.6324 - val_loss: 0.8214 - val_accuracy: 0.6581\nEpoch 5/10\n347/347 [==============================] - 22s 65ms/step - loss: 0.7769 - accuracy: 0.7033 - val_loss: 0.6875 - val_accuracy: 0.7469\nEpoch 6/10\n347/347 [==============================] - 23s 65ms/step - loss: 0.6625 - accuracy: 0.7496 - val_loss: 0.5892 - val_accuracy: 0.7805\nEpoch 7/10\n347/347 [==============================] - 22s 64ms/step - loss: 0.6156 - accuracy: 0.7684 - val_loss: 0.5593 - val_accuracy: 0.8072\nEpoch 8/10\n347/347 [==============================] - 22s 65ms/step - loss: 0.5674 - accuracy: 0.7918 - val_loss: 0.5054 - val_accuracy: 0.8260\nEpoch 9/10\n347/347 [==============================] - 23s 66ms/step - loss: 0.5697 - accuracy: 0.7938 - val_loss: 0.4656 - val_accuracy: 0.8365\nEpoch 10/10\n347/347 [==============================] - 22s 65ms/step - loss: 0.4718 - accuracy: 0.8369 - val_loss: 0.4077 - val_accuracy: 0.8516\n87/87 [==============================] - 2s 21ms/step - loss: 0.4077 - accuracy: 0.8516\nTest Loss: [0.4077472686767578, 0.8516245484352112]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Regression","metadata":{}},{"cell_type":"code","source":"import os\n# load packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\nimport platform\nif platform.system() == \"Windows\":\n    plt.rcParams['font.family'] = ['SimHei'] # Windows\nelif platform.system() == \"Darwin\":\n    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # MacOS\nplt.rcParams['axes.unicode_minus']=False \n\n# 数据文件地址\nfolder = '/kaggle/input/gas-sensor-array-temperature-modulation/gas-sensor-array-temperature-modulation'\nfiles = sorted([i for i in os.listdir(folder) if i.endswith('.csv')])\ndata = pd.concat(\n    [pd.read_csv(os.path.join(folder,file)) for file in files],axis=0\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:47:35.215167Z","iopub.execute_input":"2023-07-21T08:47:35.216188Z","iopub.status.idle":"2023-07-21T08:47:53.101106Z","shell.execute_reply.started":"2023-07-21T08:47:35.216137Z","shell.execute_reply":"2023-07-21T08:47:53.100004Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data = data.sort_values(by=['Time (s)']).head(10000).copy()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:47:53.103394Z","iopub.execute_input":"2023-07-21T08:47:53.103962Z","iopub.status.idle":"2023-07-21T08:47:53.737526Z","shell.execute_reply.started":"2023-07-21T08:47:53.103917Z","shell.execute_reply":"2023-07-21T08:47:53.736337Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# 对数据进行归一化处理\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\n\nfeatures = [ 'Humidity (%r.h.)','Flow rate (mL/min)', 'Heater voltage (V)', 'R1 (MOhm)', 'R2 (MOhm)',\n       'R3 (MOhm)', 'R4 (MOhm)', 'R5 (MOhm)', 'R6 (MOhm)', 'R7 (MOhm)',\n       'R8 (MOhm)', 'R9 (MOhm)', 'R10 (MOhm)', 'R11 (MOhm)', 'R12 (MOhm)',\n       'R13 (MOhm)', 'R14 (MOhm)']\ntarget = 'Temperature (C)'\n\n\nx_scaler = MinMaxScaler()\ndata[features] = x_scaler.fit_transform(data[features])\ny_scaler = MinMaxScaler()\ndata[[target]] = y_scaler.fit_transform(data[[target]])","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:47:53.739174Z","iopub.execute_input":"2023-07-21T08:47:53.739788Z","iopub.status.idle":"2023-07-21T08:47:53.765687Z","shell.execute_reply.started":"2023-07-21T08:47:53.739753Z","shell.execute_reply":"2023-07-21T08:47:53.764596Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nclass WindowGenerator():\n    \"\"\"A class that generates time series data\"\"\"\n    def __init__(self, input_width, label_width, shift,\n               data = None,label_columns=None,feature_columns=None):\n        # Store the raw data. pd.DataFrame type\n        self.data = data\n        # Work out the label column indices.\n        self.label_columns = label_columns\n        self.feature_columns = feature_columns\n        # Work out the window parameters.\n        self.input_width = input_width\n        self.label_width = label_width\n        self.shift = shift\n        # all cols\n        self.col_dic = {col:i for i,col in enumerate(data.columns)}\n        self.label_col_idx = [self.col_dic[col] for col in self.label_columns]\n        self.feature_col_idx = [self.col_dic[col] for col in self.feature_columns]\n        # change to numpy array\n        self.arr = data.values\n        self.total_window_size = input_width + shift\n        self.input_slice = slice(0, input_width)\n        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n        self.label_start = self.total_window_size - self.label_width\n        self.labels_slice = slice(self.label_start, None)\n        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n        self.split_window()\n        print(self)\n\n    def split_window(self):\n        self.X = []\n        self.y = []\n        for i in range(self.total_window_size,len(self.arr)):\n            window_data = self.arr[i-self.total_window_size:i]\n            self.X.append(window_data[np.ix_(self.input_indices,self.feature_col_idx)])\n            self.y.append(window_data[np.ix_(self.label_indices,self.label_col_idx)])\n        self.X = np.asarray(self.X)\n        self.y = np.asarray(self.y)\n\n    def __repr__(self):\n        return '\\n'.join([\n            f'Total window size: {self.total_window_size}',\n            f'Input indices: {self.input_indices}',\n            f'Label indices: {self.label_indices}',\n            f'Label column name(s): {self.label_columns}',\n            f'Label column index(s): {self.label_col_idx}',\n            f'Feature column name(s): {self.feature_columns}',\n            f'Feature column index(s): {self.feature_col_idx}',\n            f'Origin dataset shape: {self.arr.shape}',\n            f'X shape: {self.X.shape}',\n            f'y shape: {self.y.shape}',\n            ])\n\n# 传入一个dataframe类型\nwg = WindowGenerator(input_width=10,\n\t\t\t\t\tlabel_width=1,\n\t\t\t\t\tshift=1,\n\t\t\t\t\tlabel_columns=[target],\n\t\t\t\t\tfeature_columns=features,\n\t\t\t\t\tdata=data\n\t\t\t\t\t)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:47:53.768340Z","iopub.execute_input":"2023-07-21T08:47:53.768713Z","iopub.status.idle":"2023-07-21T08:47:54.158588Z","shell.execute_reply.started":"2023-07-21T08:47:53.768682Z","shell.execute_reply":"2023-07-21T08:47:54.157318Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Total window size: 11\nInput indices: [0 1 2 3 4 5 6 7 8 9]\nLabel indices: [10]\nLabel column name(s): ['Temperature (C)']\nLabel column index(s): [3]\nFeature column name(s): ['Humidity (%r.h.)', 'Flow rate (mL/min)', 'Heater voltage (V)', 'R1 (MOhm)', 'R2 (MOhm)', 'R3 (MOhm)', 'R4 (MOhm)', 'R5 (MOhm)', 'R6 (MOhm)', 'R7 (MOhm)', 'R8 (MOhm)', 'R9 (MOhm)', 'R10 (MOhm)', 'R11 (MOhm)', 'R12 (MOhm)', 'R13 (MOhm)', 'R14 (MOhm)']\nFeature column index(s): [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\nOrigin dataset shape: (10000, 20)\nX shape: (9989, 10, 17)\ny shape: (9989, 1, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"X = wg.X\ny = wg.y","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:47:54.160043Z","iopub.execute_input":"2023-07-21T08:47:54.160442Z","iopub.status.idle":"2023-07-21T08:47:54.165786Z","shell.execute_reply.started":"2023-07-21T08:47:54.160409Z","shell.execute_reply":"2023-07-21T08:47:54.164449Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\n\n# 拆分数据集为训练集和测试集（8:2）\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 构建LSTM回归模型\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1))  # 输出层没有使用激活函数，因为是回归问题\n\n# 编译模型\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=['mae'])\n\nprint(model.summary())\n# 训练模型\nmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data = (X_test,y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:48:20.073817Z","iopub.execute_input":"2023-07-21T08:48:20.074578Z","iopub.status.idle":"2023-07-21T08:48:45.719469Z","shell.execute_reply.started":"2023-07-21T08:48:20.074541Z","shell.execute_reply":"2023-07-21T08:48:45.718337Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_2 (LSTM)               (None, 64)                20992     \n                                                                 \n dense_4 (Dense)             (None, 32)                2080      \n                                                                 \n dense_5 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 23,105\nTrainable params: 23,105\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/10\n250/250 [==============================] - 5s 11ms/step - loss: 0.0179 - mae: 0.0677 - val_loss: 0.0021 - val_mae: 0.0352\nEpoch 2/10\n250/250 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0019 - val_mae: 0.0303\nEpoch 3/10\n250/250 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0017 - val_mae: 0.0301\nEpoch 4/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0305\nEpoch 5/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0298 - val_loss: 0.0016 - val_mae: 0.0296\nEpoch 6/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0302 - val_loss: 0.0017 - val_mae: 0.0306\nEpoch 7/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0013 - mae: 0.0296 - val_loss: 0.0016 - val_mae: 0.0289\nEpoch 8/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0297 - val_loss: 0.0016 - val_mae: 0.0302\nEpoch 9/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0298 - val_loss: 0.0020 - val_mae: 0.0362\nEpoch 10/10\n250/250 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0303 - val_loss: 0.0016 - val_mae: 0.0310\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bf76bceeec0>"},"metadata":{}}]},{"cell_type":"code","source":"# 评估模型性能\nloss = model.evaluate(X_test, y_test)\nprint(\"Test Loss:\", loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-21T08:48:50.609592Z","iopub.execute_input":"2023-07-21T08:48:50.610034Z","iopub.status.idle":"2023-07-21T08:48:50.996099Z","shell.execute_reply.started":"2023-07-21T08:48:50.609996Z","shell.execute_reply":"2023-07-21T08:48:50.994303Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0310\nTest Loss: [0.0016266002785414457, 0.030977696180343628]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
